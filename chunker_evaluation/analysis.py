import json
import os
import statistics

import matplotlib.pyplot as plt
import pandas as pd


def count_chunks(output_dir):
    """
    Counts the number of chunks generated by each chunker for each document.

    Parameters
    ----------
    output_dir : str
        Path to the directory where the generated data is saved.

    Returns
    -------
    pd.DataFrame
        A DataFrame with chunkers as rows and documents as columns,
        containing the number of chunks generated.
    """
    data = {}

    for chunker_name in os.listdir(output_dir):
        chunker_dir = os.path.join(output_dir, chunker_name)
        if os.path.isdir(chunker_dir):
            data[chunker_name] = {}
            for filename in os.listdir(chunker_dir):
                if filename.endswith("_qa_dataset.json"):
                    filepath = os.path.join(chunker_dir, filename)
                    with open(filepath, "r") as f:
                        qa_dataset = json.load(f)
                        num_chunks = len(
                            qa_dataset
                        )  # Assuming one chunk per question-answer pair
                        data[chunker_name][filename] = num_chunks

    # Create a pandas DataFrame from the data
    df = pd.DataFrame(data).T.fillna(0).astype(int)
    df.index.name = "Chunker"
    df.columns = [col.replace("_qa_dataset.json", "") for col in df.columns]

    return df

def analyze_chunk_lengths(output_dir, interactive=False):
    """
    Analyzes and plots chunk length distributions.

    Parameters
    ----------
    output_dir : str
        Path to the directory where the generated data is saved.
    """
    chunker_names = []
    all_chunk_lengths = []

    for chunker_name in os.listdir(output_dir):
        chunker_dir = os.path.join(output_dir, chunker_name)
        if os.path.isdir(chunker_dir):
            chunker_names.append(chunker_name)
            chunk_lengths_by_document = []

            for filename in os.listdir(chunker_dir):
                if filename.endswith("_qa_dataset.json"):
                    filepath = os.path.join(chunker_dir, filename)
                    with open(filepath, "r") as f:
                        qa_dataset = json.load(f)
                        chunk_lengths = [len(data["chunk"]) for data in qa_dataset]
                        chunk_lengths_by_document.append(chunk_lengths)

            all_chunk_lengths.append(chunk_lengths_by_document)

    # Plotting
    fig, axes = plt.subplots(
        len(chunker_names), 1, figsize=(10, 4 * len(chunker_names))
    )
    if len(chunker_names) == 1:
        axes = [axes]

    for i, chunker_name in enumerate(chunker_names):
        ax = axes[i]
        for j, chunk_lengths in enumerate(all_chunk_lengths[i]):
            ax.hist(chunk_lengths, bins=10, alpha=0.5, label=f"Document {j+1}")

            # Calculate and print statistics
            mean_length = statistics.mean(chunk_lengths)
            median_length = statistics.median(chunk_lengths)
            stdev_length = statistics.stdev(chunk_lengths) if len(chunk_lengths) > 1 else 0

            print(f"  {filename}:")
            print(f"    Mean chunk length: {mean_length:.2f}")
            print(f"    Median chunk length: {median_length:.2f}")
            print(f"    Standard deviation of chunk length: {stdev_length:.2f}")

        ax.set_title(f"Chunk Length Distribution for {chunker_name}")
        ax.set_xlabel("Chunk Length")
        ax.set_ylabel("Frequency")
        ax.legend()

    fig.tight_layout()
    if interactive:
        return fig, axes
    else: plt.show()